# -*- coding: utf-8 -*-
"""Titanic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JQgSHD1wfHL9nxCh3zoJ_P81eDRg33cz
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# % matplotlib inline

TRAIN_PATH="/content/drive/MyDrive/Kaggle/titanic/train.csv"
TEST_PATH="/content/drive/MyDrive/Kaggle/titanic/test.csv"
train_df= pd.read_csv(TRAIN_PATH)
test_df =  pd.read_csv(TEST_PATH)

train_df.head()

train_df.columns

train_df.describe

"""**Exploring the data**"""

sns.heatmap(train_df.isnull(),yticklabels=False,cbar=False,cmap='viridis')

sns.set_style('whitegrid')
sns.countplot(x='Survived', data=train_df, palette='rocket')

sns.set_style('whitegrid')
sns.countplot(x='Survived', hue='Sex', data=train_df, palette='rocket')

sns.set_style('whitegrid')
sns.countplot(x='Survived', hue='Pclass', data=train_df, palette='rocket')

sns.set_style('whitegrid')
sns.countplot(x='Survived', hue='Embarked', data=train_df, palette='rocket')

sns.distplot(train_df['Age'].dropna(),kde=False,color='darkred',bins=30)

train_df['Age'].hist(bins=30,color='darkred',alpha=0.7)

sns.countplot(x='SibSp',data=train_df)

"""A large number of people were travelling alone"""

train_df['Fare'].hist(color='green',bins=40,figsize=(8,4))

"""**Data Cleaning**"""

plt.figure(figsize=(12,7))
sns.boxplot(x='Pclass', y='Age', data =train_df, palette = 'winter')

def impute_age(cols):
  Age = cols[0]
  Pclass = cols[1]
  if pd.isnull(Age):

        if Pclass == 1:
            return 37

        elif Pclass == 2:
            return 29

        else:
            return 24

  else:
        return Age

def update_name(cols):
  name = cols[0]
  name_tokenized = name.split(" ")
  return name_tokenized[1]

def update_ticket(cols):
  name = cols[0]
 
  name_tokenized = name.split(" ")
  if len(name_tokenized)>1:
    return name_tokenized[0]
  else:
    return 'O' #Ordinary

train_df['Age'] = train_df[['Age','Pclass']].apply(impute_age,axis=1)

train_df['Name'] = train_df[['Name']].apply(update_name,axis=1)
train_df['Ticket'] = train_df[['Ticket']].apply(update_ticket,axis=1)

sns.heatmap(train_df.isnull(),yticklabels=False,cbar=False,cmap='viridis')

train_df.drop('Cabin',axis=1,inplace=True)

train_df.head()

train_df['Ticket'].unique()

train_df['Name'].unique()

sns.set(rc={'figure.figsize':(11.7,8.27)})
sns.set_style('whitegrid')
sns.countplot(x='Survived', hue='Name', data=train_df, palette='rocket')

sns.set_style('whitegrid')
sns.countplot(x='Survived', hue='Ticket', data=train_df, palette='rocket')

def update_name_2(cols):
  title = cols[0]
  imp_titles = ['Mr.', 'Mrs.', 'Miss.', 'Master.']
  if title in imp_titles:
    return title
  else:
    return 'O_title' #Other title

def update_ticket_2(cols):
  ticket = cols[0]
  imp_tickets=['A/5', 'PC', 'O', 'C.A.']
  if ticket in imp_tickets:
    return ticket
  else:
    return 'O_2' #2nd others category

train_df['Name'] = train_df[['Name']].apply(update_name_2,axis=1)
train_df['Ticket'] = train_df[['Ticket']].apply(update_ticket_2,axis=1)

train_df['Ticket'].unique()

train_df['Name'].unique()

sex = pd.get_dummies(train_df['Sex'],drop_first=True)
embark = pd.get_dummies(train_df['Embarked'],drop_first=True)
name = pd.get_dummies(train_df['Name'],drop_first=True)
ticket = pd.get_dummies(train_df['Ticket'],drop_first=True)

train_df.drop(['Name', 'Sex', 'Embarked', 'Ticket'],axis=1,inplace=True)

train_df = pd.concat([train_df,name,sex,ticket,embark],axis=1)

train_df.head()

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(train_df.drop('Survived',axis=1), 
                                                    train_df['Survived'], test_size=0.1, 
                                                    random_state=101)

from sklearn.linear_model import LogisticRegression

logmodel = LogisticRegression()
logmodel.fit(X_train,y_train)

predictions = logmodel.predict(X_test)

from sklearn.metrics import classification_report

print(classification_report(y_test,predictions))

test_df.head()

test_df['Age'] = test_df[['Age','Pclass']].apply(impute_age,axis=1)
test_df['Name'] = test_df[['Name']].apply(update_name,axis=1)
test_df['Ticket'] = test_df[['Ticket']].apply(update_ticket,axis=1)

test_df['Name'] = test_df[['Name']].apply(update_name_2,axis=1)
test_df['Ticket'] = test_df[['Ticket']].apply(update_ticket_2,axis=1)

test_df.drop('Cabin',axis=1,inplace=True)

sex = pd.get_dummies(test_df['Sex'],drop_first=True)
embark = pd.get_dummies(test_df['Embarked'],drop_first=True)
name = pd.get_dummies(test_df['Name'],drop_first=True)
ticket = pd.get_dummies(test_df['Ticket'],drop_first=True)

test_df.drop(['Name', 'Sex', 'Embarked', 'Ticket'],axis=1,inplace=True)
test_df = pd.concat([test_df,name, sex, ticket,embark],axis=1)
test_df.head()

sns.heatmap(test_df.isnull(),yticklabels=False,cbar=False,cmap='viridis')

from sklearn.impute import SimpleImputer

# Imputation
my_imputer = SimpleImputer()

imputed_train_df = pd.DataFrame(my_imputer.fit_transform(X_train))
imputed_test_df = pd.DataFrame(my_imputer.transform(test_df))

# Imputation removed column names; put them back
imputed_test_df.columns = test_df.columns

sns.heatmap(imputed_test_df.isnull(),yticklabels=False,cbar=False,cmap='viridis')

imputed_test_df.head()

predictions_ = logmodel.predict(imputed_test_df)

submission = pd.DataFrame(
    {
        'PassengerId':test_df['PassengerId'],
        'Survived':predictions_
    }
)



submission.to_csv('Titanic_Submission_1.csv', index=False)

a = "Joshi, Mr. Chetan"
A_list = a.split(" ")
A_list

A_list[1]

from sklearn.ensemble import RandomForestClassifier
clf=RandomForestClassifier(n_estimators=300)
clf.fit(X_train,y_train)

predictions = clf.predict(X_test)

print(classification_report(y_test,predictions))

predictions_ = clf.predict(imputed_test_df)

submission = pd.DataFrame(
    {
        'PassengerId':test_df['PassengerId'],
        'Survived':predictions_
    }
)

submission.to_csv('Titanic_Submission_2.csv', index=False)

from sklearn import datasets

#Load dataset
iris = datasets.load_iris()
iris.feature_names

X_train.columns

feature_imp = pd.Series(clf.feature_importances_,index=X_train.columns).sort_values(ascending=False)

feature_imp

